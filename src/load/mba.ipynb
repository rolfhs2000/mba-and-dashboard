{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3678b6",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1339d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Nessessary Libraries\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff39b1c",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef712387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"../../data/input/mba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select needed columns & Rename columns & Re-arrange columns\n",
    "df = df[['Nhà sản xuất', 'Khách hàng', 'Email khách hàng', 'Ngày', 'Nguồn lưu lượng (Traffic)', 'UTM_source', 'Chi nhánh', 'Loại sản phẩm', 'Tỉnh thành', 'Đơn hàng', 'Sản phẩm', 'Quận huyện vận chuyển', 'Phiên bản', 'T.trạng t.toán', 'T.trạng đ.hàng', 'Phương thức thanh toán', 'Doanh thu', 'Tiền khuyến mãi', 'Doanh thu thuần', 'Tổng hóa đơn', 'Đã thu', 'Số lượng', 'Vận chuyển']]\n",
    "df.columns = ['manufacturer', 'customer_name', 'email', 'order_date', 'traffic_source', 'utm_source', 'warehouse', 'category_name', 'province', 'order_id', 'product_name', 'district', 'product_type', 'payment_status', 'order_status', 'payment_method', 'amount', 'discount', 'net_amount', 'final_amount', 'received_amount', 'quantity', 'delivery_amount']\n",
    "df = df[['manufacturer', 'customer_name', 'email', 'order_id', 'order_date', 'product_name', 'product_type', 'category_name', 'quantity', 'amount', 'discount', 'net_amount', 'delivery_amount', 'final_amount', 'received_amount', 'traffic_source', 'utm_source', 'warehouse', 'province', 'district', 'payment_status', 'order_status', 'payment_method']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83d8a0",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "print('=>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> .info()\\n',df.info())\n",
    "print('=>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> .head()\\n',df.head())\n",
    "print('=>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> .describe()\\n',df.describe())\n",
    "print('=>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> .columns()\\n',df.columns)\n",
    "# Check Duplicated Rows => not found any duplicated rows\n",
    "print('=>>>>>>>> DF\\n',df[df.duplicated()])\n",
    "# Check Duplicated Order ID => found some duplicated order id\n",
    "print('=>>>>>>>> Check `order_id`\\n', df[df.order_id.duplicated()].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.traffic_source.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0573134d",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a81da8",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59278e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: Remove duplicated (`order_id`, `product_name`) with amount = 0 (keep all duplicated rows with amount != 0) according to business requirement.\n",
    "df=df[df.duplicated(subset=['order_id', 'product_name'], keep=False) & (df.amount != 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726df913",
   "metadata": {},
   "source": [
    "## Process fields & Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51307b62",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "def clean_text_field(text, convention=None):\n",
    "    \"\"\"\n",
    "    Clean text field by removing leading/trailing spaces, chuẩn hóa unicode và chuyển đổi theo convention.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Chuẩn hóa unicode\n",
    "        text = unicodedata.normalize('NFC', text)\n",
    "        if convention == 'title':\n",
    "            text = text.strip().title()\n",
    "        elif convention == 'capitalize':\n",
    "            text = text.strip().capitalize()\n",
    "        else:\n",
    "            text = text.strip()\n",
    "    else:\n",
    "        text = 'error'  # Xử lý nghiệp vụ sau\n",
    "    return text\n",
    "\n",
    "\n",
    "import re\n",
    "def is_valid_email(email):\n",
    "    \"\"\"Kiểm tra email có hợp lệ hay không.\"\"\"\n",
    "    if not isinstance(email, str):\n",
    "        return False\n",
    "    pattern = r'^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$'\n",
    "    return re.match(pattern, email) is not None\n",
    "\n",
    "def handle_invalid_email(email):\n",
    "    \"\"\"Kiểm tra tính hợp lệ của email. Nếu email không hợp lệ, trả về 'error' => Xử lý nghiệp vụ sau.\"\"\"\n",
    "    if is_valid_email(email):\n",
    "        return email\n",
    "    return 'error'\n",
    "\n",
    "def mapping_text(text, _mapping_text_dict, remove_special_tail=None, convention=None):\n",
    "    \"\"\" Clean text, replace pattern, mapping value according to business rules. \"\"\"\n",
    "    if not isinstance(text, str): # Check if text is not string\n",
    "        return 'error'\n",
    "    else:\n",
    "        if remove_special_tail != None: # Remove special tail if specified\n",
    "            text = re.sub('--', 'unknown', text) # Replace '--' -> 'unknown' according to business rules.\n",
    "            pattern=rf'{remove_special_tail}+$'\n",
    "            text = re.sub(pattern, '', text)\n",
    "        text = _mapping_text_dict.get(text.lower(), text)\n",
    "        if convention == 'lower': # Convert to lower case if specified\n",
    "            return text.lower()\n",
    "        else:\n",
    "            return text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35c1de",
   "metadata": {},
   "source": [
    "## Config: Mapping text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b589d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_text_dict = {\n",
    "    'fb': 'Facebook',\n",
    "    'facebook': 'Facebook'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb3dce",
   "metadata": {},
   "source": [
    "## Pre-processing each fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca2c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `manufacturer`\n",
    "df['manufacturer'] = df['manufacturer'].apply(lambda x: clean_text_field(x, convention='title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `customer_name`\n",
    "df['customer_name'] = df['customer_name'].apply(lambda x: clean_text_field(x, convention='title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `email`\n",
    "df['email'] = df['email'].apply(lambda x: clean_text_field(x)) # Clean text field\n",
    "df['email'] = df['email'].apply(lambda x: handle_invalid_email(x)) # Handle invalid email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d9ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `order_date`\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], format='%d/%m/%Y') # Convert to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2834db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `category_name`\n",
    "df['category_name'] = df['category_name'].apply(lambda x: clean_text_field(x, convention='capitalize')) # Clean text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `product_name`\n",
    "df['product_name'] = df['product_name'].apply(lambda x: clean_text_field(x)) # Clean text field\n",
    "df['product_name'] = df['product_name'].apply(lambda x: mapping_text(x, mapping_text_dict, remove_special_tail='-')) # Mapping giá trị cột 'product_name' theo mapping_text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `product_type`\n",
    "df['product_type'] = df['product_type'].apply(lambda x: clean_text_field(x)) # Clean text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fcaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `traffic_source`\n",
    "df['traffic_source'] = df['traffic_source'].apply(lambda x: clean_text_field(x))\n",
    "# Mapping giá trị cột 'traffic_source' theo mapping_text_dict\n",
    "df['traffic_source'] = df['traffic_source'].apply(lambda x: mapping_text(x, mapping_text_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d5f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `utm_source`\n",
    "df['utm_source'] = df['utm_source'].apply(lambda x: clean_text_field(x)) # Clean text field\n",
    "df['utm_source'] = df['utm_source'].apply(lambda x: mapping_text(x, mapping_text_dict, remove_special_tail='-', convention='lower'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a507d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `warehouse`\n",
    "df['warehouse'] = df['warehouse'].apply(lambda x: clean_text_field(x)) # Clean text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `province`\n",
    "df['province'] = df['province'].apply(lambda x: clean_text_field(x)) # Clean text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `district`\n",
    "df['district'] = df['district'].apply(lambda x: clean_text_field(x)) # Clean text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949951c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `payment_status`\n",
    "df['payment_status'] = df['payment_status'].apply(lambda x: clean_text_field(x)) # Clean text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca908e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `order_status`\n",
    "df['order_status'] = df['order_status'].apply(lambda x: clean_text_field(x)) # Clean text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a706187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: `payment_method`\n",
    "df['payment_method'] = df['payment_method'].apply(lambda x: clean_text_field(x)) # Clean text field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab5142",
   "metadata": {},
   "source": [
    "## Convert data source's schema to Dimensional Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4f5965",
   "metadata": {},
   "source": [
    "## Extract data according to Dimensional Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14edafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `customers`\n",
    "# Identify customer by their email -> Generate `customer_id``\n",
    "customers_df = df[['email','customer_name']].sort_values(by=['email']).drop_duplicates(subset=(['email'])).reset_index(drop=True)\n",
    "customers_df['id'] = customers_df.index + 1\n",
    "# Rename columns\n",
    "customers_df.columns = ['email', 'customer_name', 'customer_id']\n",
    "# Re-arrange columns\n",
    "customers_df = customers_df[['customer_id', 'customer_name', 'email']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `manufacturers`\n",
    "# Identify manufacturer by their email -> Generate `manufacturer_id``\n",
    "manufacturers_df = df[['manufacturer']].sort_values(by=['manufacturer']).drop_duplicates().reset_index(drop=True)\n",
    "manufacturers_df['id'] = manufacturers_df.index + 1\n",
    "# Rename columns\n",
    "manufacturers_df.columns = ['manufacturer_name', 'manufacturer_id']\n",
    "# Re-arrange columns\n",
    "manufacturers_df = manufacturers_df[['manufacturer_id', 'manufacturer_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `categories`\n",
    "categories_df = df[['category_name']].sort_values(by=['category_name']).drop_duplicates().reset_index(drop=True)\n",
    "categories_df['id'] = categories_df.index + 1\n",
    "# Rename columns\n",
    "categories_df.columns = ['category_name', 'category_id']\n",
    "# Re-arrange columns\n",
    "categories_df = categories_df[['category_id', 'category_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20376f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `products`\n",
    "products_df = df[['product_name']].sort_values(by=['product_name']).drop_duplicates().reset_index(drop=True)\n",
    "products_df['id'] = products_df.index + 1\n",
    "# Rename columns\n",
    "products_df.columns = ['product_name', 'product_id']\n",
    "# Re-arrange columns\n",
    "products_df = products_df[['product_id', 'product_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcff780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `skus`\n",
    "skus_df = df[['product_name', 'product_type']].sort_values(by=['product_name', 'product_type']).drop_duplicates().reset_index(drop=True)\n",
    "skus_df['id'] = skus_df.index + 1\n",
    "\n",
    "skus_df = skus_df.merge(products_df, on='product_name', how='left') # Map `product_name' to 'product_id'\n",
    "skus_df['sku_description'] = skus_df['product_name'] + ' | ' + skus_df['product_type']\n",
    "\n",
    "# Rename columns\n",
    "skus_df.columns = ['product_name', 'product_type', 'sku_id', 'product_id', 'sku_description']\n",
    "# Select and Re-arrange columns\n",
    "skus_df = skus_df[['sku_id', 'sku_description', 'product_id', 'product_name', 'product_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `payment_methods`\n",
    "payment_methods_df = df[['payment_method']].sort_values(by=['payment_method']).drop_duplicates().reset_index(drop=True)\n",
    "payment_methods_df['id'] = payment_methods_df.index + 1\n",
    "# Rename columns\n",
    "payment_methods_df.columns = ['description', 'payment_method']\n",
    "# Re-arrange columns\n",
    "payment_methods_df = payment_methods_df[['payment_method', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ff5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `payment_status`\n",
    "payment_status_df = df[['payment_status']].sort_values(by=['payment_status']).drop_duplicates().reset_index(drop=True)\n",
    "payment_status_df['id'] = payment_status_df.index + 1\n",
    "# Rename columns\n",
    "payment_status_df.columns = ['description', 'payment_status']\n",
    "# Re-arrange columns\n",
    "payment_status_df = payment_status_df[['payment_status', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2501227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `order_status`\n",
    "order_status_df = df[['order_status']].sort_values(by=['order_status']).drop_duplicates().reset_index(drop=True)\n",
    "order_status_df['id'] = order_status_df.index + 1\n",
    "# Rename columns\n",
    "order_status_df.columns = ['description', 'order_status']\n",
    "# Re-arrange columns\n",
    "order_status_df = order_status_df[['order_status', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `warehouses`\n",
    "warehouses_df = df[['warehouse']].sort_values(by=['warehouse']).drop_duplicates().reset_index(drop=True)\n",
    "warehouses_df['id'] = warehouses_df.index + 1\n",
    "# Rename columns\n",
    "warehouses_df.columns = ['warehouse_name', 'warehouse_id']\n",
    "# Re-arrange columns\n",
    "warehouses_df = warehouses_df[['warehouse_id', 'warehouse_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ba05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `provinces`\n",
    "provinces_df = df[['province']].sort_values(by=['province']).drop_duplicates().reset_index(drop=True)\n",
    "provinces_df['id'] = provinces_df.index + 1\n",
    "# Rename columns\n",
    "provinces_df.columns = ['province_name', 'province_id']\n",
    "# Re-arrange columns\n",
    "provinces_df = provinces_df[['province_id', 'province_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional: `districts`\n",
    "districts_df = df[['province', 'district']].sort_values(by=['province', 'district']).drop_duplicates().reset_index(drop=True)\n",
    "districts_df['id'] = districts_df.index + 1\n",
    "districts_df = districts_df.merge(provinces_df, left_on='province', right_on='province_name', how='left') # Map `province_name' to 'province_id'\n",
    "# Rename columns\n",
    "districts_df.columns = ['province', 'district_name', 'district_id', 'province_id', 'province_name']\n",
    "# Select & Re-arrange columns\n",
    "districts_df = districts_df[['district_id', 'district_name', 'province_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fact Table: `sale_details_df`\n",
    "# Map `field_name` to `field_id`\n",
    "\n",
    "sale_details_df = df\n",
    "\n",
    "# Map `email` to `customer_id`\n",
    "sale_details_df = sale_details_df.merge(customers_df[['email', 'customer_id']], on='email', how='left')\n",
    "\n",
    "# Map (`product_name`,`product_type`) to `sku_id`\n",
    "sale_details_df = sale_details_df.merge(skus_df[['sku_id', 'product_name', 'product_type']], on=['product_name', 'product_type'], how='left')\n",
    "\n",
    "# Map `product_name` to `product_id`\n",
    "sale_details_df = sale_details_df.merge(products_df[['product_id', 'product_name']], on='product_name', how='left')\n",
    "\n",
    "# Map `category_name` to `category_id`\n",
    "sale_details_df = sale_details_df.merge(categories_df, on='category_name', how='left')\n",
    "\n",
    "# Map `manufacturer` to `manufacturer_id`\n",
    "sale_details_df = sale_details_df.merge(manufacturers_df, left_on='manufacturer', right_on='manufacturer_name', how='left')\n",
    "\n",
    "# Map `warehouse` to `warehouse_id`\n",
    "sale_details_df = sale_details_df.merge(warehouses_df, left_on='warehouse', right_on='warehouse_name', how='left')\n",
    "\n",
    "# Map `payment_method(description)` to `payment_method(id)``\n",
    "sale_details_df = sale_details_df.merge(payment_methods_df, left_on='payment_method', right_on='description', how='left')\n",
    "\n",
    "# Map `payment_status(description)` to `payment_status(id)`\n",
    "sale_details_df = sale_details_df.merge(payment_status_df, left_on='payment_status', right_on='description', how='left')\n",
    "\n",
    "# Map `order_status(description)` to `order_status(id)`\n",
    "sale_details_df = sale_details_df.merge(order_status_df, left_on='order_status', right_on='description', how='left')\n",
    "\n",
    "# Map `province` to `province_id`\n",
    "sale_details_df = sale_details_df.merge(provinces_df, left_on='province', right_on='province_name', how='left')\n",
    "\n",
    "# Map `district` to `district_id` (need to map `province_id` first to get `province_id` for mapping `district_id`)\n",
    "sale_details_df = sale_details_df.merge(districts_df, left_on=['district', 'province_id'], right_on=['district_name', 'province_id'], how='left')\n",
    "\n",
    "# Generate `id` for `sale_details_df`\n",
    "sale_details_df['id'] = sale_details_df.index + 1\n",
    "\n",
    "# Select &  Re-arrange columns\n",
    "sale_details_df = sale_details_df[['id', 'order_id', 'order_date', 'customer_id', 'sku_id', 'product_id', 'category_id', 'manufacturer_id','warehouse_id', 'payment_method_y', 'payment_status_y','order_status_y', 'district_id', 'province_id', 'quantity', 'amount', 'discount', 'net_amount', 'delivery_amount', 'final_amount', 'received_amount', 'traffic_source', 'utm_source']].reset_index(drop=True)\n",
    "\n",
    "# Rename columns\n",
    "sale_details_df.columns = ['id', 'order_id', 'order_date', 'customer_id', 'sku_id', 'product_id', 'category_id', 'manufacturer_id','warehouse_id', 'payment_method', 'payment_status','order_status', 'delivery_district_id', 'delivery_province_id', 'quantity', 'amount', 'discount', 'net_amount', 'delivery_amount', 'final_amount', 'received_amount', 'traffic_source', 'utm_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74601d",
   "metadata": {},
   "source": [
    "# Connect to DB & Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903dbb7",
   "metadata": {},
   "source": [
    "## Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d63d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyodbc and check available drivers\n",
    "import pyodbc\n",
    "print(pyodbc.drivers())\n",
    "\n",
    "# Import DB access information\n",
    "import sys\n",
    "sys.path.append('../db_connection/connectors')\n",
    "from mysql_admin import SERVER, PORT, DATABASE, USERNAME, PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DB\n",
    "conn_str = (\n",
    "    'DRIVER={MySQL ODBC 9.4 Unicode Driver};'\n",
    "    f'SERVER={SERVER};'\n",
    "    f'PORT={PORT};'\n",
    "    f'DATABASE={DATABASE};'\n",
    "    f'USER={USERNAME};'\n",
    "    f'PASSWORD={PASSWORD};'\n",
    "    'OPTION=3;'\n",
    ")\n",
    "\n",
    "conn = pyodbc.connect(conn_str)\n",
    "print(\"Connect Successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744be96",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c750a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de78c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table\n",
    "import os\n",
    "\n",
    "# Đọc script tạo bảng từ file SQL\n",
    "sql_path = os.path.abspath('../../sql/ddl/create_table_replace.sql')\n",
    "with open(sql_path, 'r', encoding='utf-8') as f:\n",
    "    create_table_sql = f.read()\n",
    "\n",
    "# Thực thi script tạo bảng\n",
    "cursor = conn.cursor()\n",
    "for statement in create_table_sql.split(';'):\n",
    "    stmt = statement.strip()\n",
    "    if stmt:\n",
    "        try:\n",
    "            cursor.execute(stmt)\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing statement: {stmt}\\n{e}\")\n",
    "conn.commit()\n",
    "print(\"Tables created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab60687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data từ các dataframe vào các bảng\n",
    "def insert_df_to_db(df, table, conn, if_exists='append'):\n",
    "    # Sử dụng sqlalchemy để insert nhanh hơn (nếu có)\n",
    "    try:\n",
    "        from sqlalchemy import create_engine\n",
    "        engine_str = f\"mysql+pyodbc://{USERNAME}:{PASSWORD}@{SERVER}:{PORT}/{DATABASE}?driver=MySQL+ODBC+9.4+Unicode+Driver\"\n",
    "        engine = create_engine(engine_str)\n",
    "        df.to_sql(table, con=engine, if_exists=if_exists, index=False)\n",
    "        print(f\"Inserted {len(df)} rows into {table}\")\n",
    "    except ImportError:\n",
    "        # Nếu không có sqlalchemy, dùng pyodbc thủ công\n",
    "        cols = ','.join(df.columns)\n",
    "        placeholders = ','.join(['?'] * len(df.columns))\n",
    "        for row in df.itertuples(index=False, name=None):\n",
    "            cursor.execute(f\"INSERT INTO {table} ({cols}) VALUES ({placeholders})\", row)\n",
    "        conn.commit()\n",
    "        print(f\"Inserted {len(df)} rows into {table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd948ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert lần lượt các bảng dimension và fact\n",
    "insert_df_to_db(customers_df, 'customers', conn)\n",
    "insert_df_to_db(manufacturers_df, 'manufacturers', conn)\n",
    "insert_df_to_db(categories_df, 'categories', conn)\n",
    "insert_df_to_db(products_df, 'products', conn)\n",
    "insert_df_to_db(skus_df, 'skus', conn)\n",
    "insert_df_to_db(payment_methods_df, 'payment_methods', conn)\n",
    "insert_df_to_db(payment_status_df, 'payment_status', conn)\n",
    "insert_df_to_db(order_status_df, 'order_status', conn)\n",
    "insert_df_to_db(warehouses_df, 'warehouses', conn)\n",
    "insert_df_to_db(provinces_df, 'provinces', conn)\n",
    "insert_df_to_db(districts_df, 'districts', conn)\n",
    "insert_df_to_db(sale_details_df, 'sale_details', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50591ac",
   "metadata": {},
   "source": [
    "# Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194332c",
   "metadata": {},
   "source": [
    "# FP-Growth Algorithm\n",
    "Cài đặt và chạy thuật toán FP-Growth để phân tích luật kết hợp (association rules) từ dữ liệu giao dịch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b550b3d",
   "metadata": {},
   "source": [
    "## Giải thích thuật toán FP-Growth và các chỉ số\n",
    "**FP-Growth** (Frequent Pattern Growth) là một thuật toán khai phá tập mục phổ biến (frequent itemsets) trong dữ liệu giao dịch, thường dùng trong phân tích giỏ hàng (market basket analysis). Thuật toán này giúp tìm ra các nhóm sản phẩm thường được mua cùng nhau mà không cần sinh tất cả các tập con ứng viên như Apriori, do đó nhanh và tiết kiệm bộ nhớ hơn.\n",
    "\n",
    "### Ý nghĩa các chỉ số:\n",
    "- **Support (Độ phổ biến):** Tỷ lệ số giao dịch chứa tập mục so với tổng số giao dịch. Support cao nghĩa là tập mục xuất hiện thường xuyên.\n",
    "- **Confidence (Độ tin cậy):** Xác suất rằng khi khách hàng mua tập mục A thì cũng mua tập mục B. Công thức: confidence(A→B) = support(A∪B) / support(A).\n",
    "- **Lift (Độ nâng):** Đo lường mức độ liên kết thực sự giữa A và B so với kỳ vọng nếu A và B độc lập. Lift > 1 nghĩa là A và B có mối liên hệ mạnh hơn ngẫu nhiên, lift < 1 là yếu hơn ngẫu nhiên.\n",
    "\n",
    "### Ứng dụng\n",
    "- Phát hiện các nhóm sản phẩm thường được mua cùng nhau để đề xuất bán chéo, tối ưu trưng bày sản phẩm, xây dựng chương trình khuyến mãi,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cài đặt thư viện mlxtend nếu chưa có\n",
    "# # !pip install mlxtend\n",
    "\n",
    "# # Chuẩn bị dữ liệu giao dịch cho FP-Growth\n",
    "# from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "# from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Giả sử mỗi order_id là một giao dịch, lấy danh sách sản phẩm theo order_id\n",
    "# transactions = df.groupby('order_id')['product_name'].apply(list).tolist()\n",
    "\n",
    "# # Mã hóa dữ liệu giao dịch\n",
    "# te = TransactionEncoder()\n",
    "# te_ary = te.fit(transactions).transform(transactions)\n",
    "# df_tf = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# # Chạy FP-Growth để tìm tập phổ biến\n",
    "# frequent_itemsets = fpgrowth(df_tf, min_support=0.01, use_colnames=True)\n",
    "# print('=>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> frequent_itemsets\\n',frequent_itemsets.head())\n",
    "\n",
    "# # Sinh luật kết hợp\n",
    "# rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "# print('=>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> rules\\n',rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a35d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules[['antecedents', 'consequents', 'antecedent support', 'consequent support', 'support', 'confidence', 'lift']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
